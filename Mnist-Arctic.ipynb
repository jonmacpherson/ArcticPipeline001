{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A demonstration of ArcticPipeline using the Mnist dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydicom\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/7b/6ed88f82dd33a32cdb43432dab7f84fcd40c49d63251442b3cfe0be983d4/pydicom-2.1.1-py3-none-any.whl (1.9MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9MB 14.2MB/s eta 0:00:01     |████████████████████████▎       | 1.4MB 14.2MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pydicom\n",
      "Successfully installed pydicom-2.1.1\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 20.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pydicom\n",
    "import arcticpipeline001 as ap\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BASICCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, image_size=100, features=5):\n",
    "        \n",
    "        super(BASICCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # x is not your typical x, rather it is a dictionary of feature groups. Feature groups allow data to be transferred from the \n",
    "        # data frame to the learning network in discreate groupings, for example for networks that have multiple stages. \n",
    "        \n",
    "        # The network should be written in a way that pulls in these seperate feature groups as needed. \n",
    "        # \n",
    "        x = x['mnist_image'][0]\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return F.log_softmax(x)\n",
    "            \n",
    "    \n",
    "gpu = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "state_model = BASICCNN().to(gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA cpu\n",
      "Setting the dataframe:  train to dataframe containing:  60000\n",
      "Setting the dataframe:  test to dataframe containing:  10000\n",
      "Setting the dataframe:  all to dataframe containing:  70000\n",
      "Arctic_Pipeline.show_state() is set to inactive. To turn it on, use .show_state(active=True) in the compose method\n",
      "Arctic_Pipeline.show_state() is set to inactive. To turn it on, use .show_state(active=True) in the compose method\n",
      "ArcticPipeline @: /storage/mnist-arctic/dataset/\n",
      "Bucket: train Len:60000\n",
      "Bucket: test Len:10000\n",
      "Bucket: val Len:0\n",
      "Bucket: all Len:70000\n",
      " setting network to BASICCNN(\n",
      "  (conv1): Conv2d(3, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mnist_arctic = ap.ArcticPipeline(batch_size=128, num_workers=0, pin_memory=False, shuffle=True)\n",
    "mnist_arctic.data_mode = \"train\"\n",
    "\n",
    "\n",
    "\n",
    "mnist_arctic.import_dataset(\"/storage/mnist-arctic/dataset/\")\n",
    "\n",
    "mnist_arctic.data_mode = \"train\"\n",
    "mnist_arctic.image_field = \"filename\"\n",
    "\n",
    "\n",
    "mnist_arctic.define_process_image_command_list([])\n",
    "\n",
    "\n",
    "mnist_arctic.compose_data(bucket_list=['train', 'test'], \n",
    "                          command_list=[\n",
    "    ('List Current Dataset',  mnist_arctic.show_state(n=5, active=False)),\n",
    "                              \n",
    "                          ])\n",
    "    \n",
    "# do not modify data after _init_learn, as it's too late!\n",
    "                              \n",
    "mnist_arctic._init_learn(y_label_column = 'label', \n",
    "                                                 network = state_model,\n",
    "                                                 loss_function = nn.CrossEntropyLoss(),\n",
    "                                                 feature_group_dict = {'mnist_image': ['_img_from_file']}\n",
    "                                                      )\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  0%|          | 0/469 [00:00<02:28,  3.16it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0, train BCE: 0.4982\n",
      "Eval Mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/469 [00:25<1:01:15,  7.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              val BCE: 35.7090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/469 [00:00<01:43,  4.53it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   1, train BCE: 0.2741\n",
      "Eval Mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/469 [00:17<42:14,  5.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              val BCE: 29.9480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/469 [00:00<01:58,  3.96it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   2, train BCE: 0.2365\n",
      "Eval Mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/469 [00:17<43:09,  5.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              val BCE: 28.4863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/469 [00:00<01:45,  4.44it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   3, train BCE: 0.2185\n",
      "Eval Mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/469 [00:18<43:23,  5.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              val BCE: 23.6791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/469 [00:00<01:43,  4.52it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   4, train BCE: 0.2059\n",
      "Eval Mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/469 [00:17<43:02,  5.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              val BCE: 23.8177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/469 [00:00<01:46,  4.40it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   5, train BCE: 0.2012\n",
      "Eval Mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/469 [00:17<41:36,  5.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              val BCE: 24.6010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/469 [00:00<01:52,  4.18it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   6, train BCE: 0.1924\n",
      "Eval Mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/469 [00:17<42:19,  5.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              val BCE: 22.5677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/469 [00:00<01:43,  4.53it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   7, train BCE: 0.1799\n",
      "Eval Mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/469 [00:17<42:28,  5.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              val BCE: 21.0578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/469 [00:00<01:47,  4.35it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   8, train BCE: 0.1791\n",
      "Eval Mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/469 [00:18<43:34,  5.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              val BCE: 23.0754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/469 [00:00<01:44,  4.48it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   9, train BCE: 0.1740\n",
      "Eval Mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/469 [00:17<01:44,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              val BCE: 19.7928\n",
      "Predict Mode: all\n",
      "Actual Value: tensor([1, 8, 1, 9, 3, 5, 0, 8, 1, 7, 4, 4, 7, 0, 3, 3, 7, 8, 3, 4, 8, 1, 5, 3,\n",
      "        8, 3, 4, 1, 1, 8, 8, 4, 1, 1, 2, 3, 3, 4, 0, 5, 7, 0, 0, 3, 3, 5, 9, 1,\n",
      "        6, 1, 4, 6, 6, 8, 8, 1, 6, 1, 1, 8, 8, 9, 6, 5, 5, 9, 5, 7, 9, 9, 5, 2,\n",
      "        8, 4, 5, 0, 5, 5, 7, 9, 0, 4, 1, 8, 9, 5, 1, 6, 7, 8, 9, 6, 5, 2, 4, 9,\n",
      "        2, 7, 3, 6, 3, 9, 3, 3, 1, 3, 1, 8, 7, 3, 2, 6, 5, 8, 4, 1, 0, 6, 1, 1,\n",
      "        4, 4, 2, 5, 5, 9, 2, 6]) Prediction: tensor([1, 8, 1, 9, 3, 5, 0, 8, 1, 7, 4, 4, 7, 0, 3, 3, 7, 8, 3, 4, 8, 1, 5, 3,\n",
      "        8, 3, 4, 1, 1, 8, 8, 4, 1, 1, 2, 3, 3, 4, 0, 5, 7, 0, 0, 3, 3, 5, 4, 1,\n",
      "        6, 1, 4, 6, 6, 8, 8, 1, 6, 1, 1, 8, 8, 9, 6, 5, 5, 9, 5, 7, 9, 9, 5, 2,\n",
      "        8, 4, 5, 0, 5, 5, 7, 9, 0, 4, 1, 8, 9, 5, 1, 6, 7, 8, 9, 6, 5, 2, 4, 9,\n",
      "        2, 7, 3, 6, 3, 9, 3, 3, 1, 3, 1, 8, 7, 3, 2, 6, 5, 8, 4, 1, 0, 6, 1, 1,\n",
      "        4, 4, 2, 5, 5, 9, 2, 6])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mnist_arctic.data_mode = \"train\"\n",
    "mnist_arctic.fit(epochs=10)\n",
    "mnist_arctic.predict(\"all\",1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
